{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "#https://pypi.org/project/geopy/\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# built in api \n",
    "import foursquare as fs\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Foursquare Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('41.8755616,-87.6244212', 41.8755616, -87.6244212)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputLocation = 'Chicago, IL'\n",
    "\n",
    "def get_coords(inputLocation):\n",
    "    geolocator = Nominatim(user_agent=\"my_user_agent\")\n",
    "    location = geolocator.geocode(inputLocation)\n",
    "    latitude = location.latitude\n",
    "    longitude = location.longitude\n",
    "    latitude_str = str(location.latitude)\n",
    "    longitude_str = str(location.longitude)\n",
    "    ll = latitude_str + ',' + longitude_str\n",
    "    return ll, latitude, longitude\n",
    "\n",
    "get_coords(inputLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Address\n",
      "Chicago, Cook County, Illinois, United States\n",
      "\n",
      "Latitude & Longitude\n",
      "(41.8755616, -87.6244212)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "geolocator = Nominatim(user_agent=\"my_user_agent\")\n",
    "location = geolocator.geocode(inputLocation)\n",
    "print(f'Location Address\\n{location.address}\\n')\n",
    "print(f'Latitude & Longitude\\n{(location.latitude, location.longitude)}\\n')\n",
    "# print(location.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foursquare_api():\n",
    "    with open('foursquare_keys.txt', 'r') as f:\n",
    "        CLIENT_ID, CLIENT_SECRET = [lines.strip() for lines in f.readlines()]\n",
    "\n",
    "    # VERSION = '20180605' # FOURSQUARE API VERSION\n",
    "    VERSION = '20201112' # FOURSQUARE API VERSION\n",
    "\n",
    "    # Construct the client object\n",
    "    client = fs.Foursquare(client_id=CLIENT_ID, \n",
    "                           client_secret=CLIENT_SECRET, \n",
    "                           version=VERSION)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://developer.foursquare.com/docs/api-reference/venues/search/#parameters\n",
    "def explore_venues(client, inputLocation, limit=100, radius=250):\n",
    "    '''function to get n-places using explore in foursquare, where n is the limit when calling the function.\n",
    "    This returns a pandas dataframe with name, city, categories, address, Latitude, Longitude.\n",
    "    Arguments: client (foursquare_api()), inputLocation (city, state) , limit (defaults to 100), radius (defaults to a city-wide area)\n",
    "    '''\n",
    "    \n",
    "    ll = get_coords(inputLocation)[0]\n",
    "    params={'ll':ll,\n",
    "            'limit':limit, \n",
    "            'intent' : 'browse',\n",
    "            'radius':radius, \n",
    "           }\n",
    "    venues = client.venues.explore(params)\n",
    "    venues = venues['groups'][0]['items']\n",
    "    venues = json_normalize(venues)\n",
    "    filtered_cols = ['venue.name',\n",
    "                     'venue.location.city',\n",
    "                     'venue.categories',\n",
    "                     'venue.location.address',\n",
    "                     'venue.location.lat', \n",
    "                     'venue.location.lng']\n",
    "    venues = venues.loc[:, filtered_cols]\n",
    "    venues['venue.categories'] = [value[0]['name'] for i, value in venues['venue.categories'].items()]\n",
    "    venues.columns = [col.split(\".\")[-1] for col in venues.columns]\n",
    "\n",
    "    \n",
    "    return venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'foursquare_keys.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-975e579a2b9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexplore_venues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoursquare_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Chicago, IL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-b6a2f14dc807>\u001b[0m in \u001b[0;36mfoursquare_api\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfoursquare_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foursquare_keys.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mCLIENT_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIENT_SECRET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# VERSION = '20180605' # FOURSQUARE API VERSION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'foursquare_keys.txt'"
     ]
    }
   ],
   "source": [
    "explore_venues(foursquare_api(), 'Chicago, IL', radius=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_venues(foursquare_api(), 'Brook Park, OH', radius=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# City Data Web Scraping\n",
    "+ http://www.city-data.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull data from hgraph \n",
    "def pull_value(hg, item_pos):\n",
    "    '''function to pull data from hgraph '''\n",
    "    return hg[item_pos].find('table').find_all('tr')[0].find_all('td')[1].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['med household income'\n",
    "        ,'med rent'\n",
    "        ,'males'\n",
    "        ,'med age males'\n",
    "        ,'med age females'\n",
    "        ,'avg household size'\n",
    "        ,'pct family household'\n",
    "        ,'pct married couple'\n",
    "        ,'pct families with children'\n",
    "        ,'pct single mother'\n",
    "        ,'pct never married males > 15'\n",
    "        ,'pct never married females > 15'\n",
    "        ,'pct not speak English well'\n",
    "        ,'pct born in state'\n",
    "        ,'pct born in another us state'\n",
    "        ,'pct native residents born outside us'\n",
    "        ,'pct foreign born residents'\n",
    "        ,'avg number of cars houses'\n",
    "        ,'avg number of cars apts'\n",
    "        ,'pct units mortgage']\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://developer.foursquare.com/docs/api-reference/venues/search/#parameters\n",
    "def pull_neighborhood_data(url):\n",
    "    '''function to extract all data for a neighborhood from page URL'''\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    row_data = soup.find(class_='row')\n",
    "    item = row_data.find(class_='content-item')\n",
    "    # extract area and population\n",
    "    dictionary = {}\n",
    "    for i in item.find_all('b'):\n",
    "        try:\n",
    "            key = i.text.strip()\n",
    "            value = i.next_sibling.strip()\n",
    "            dictionary[key] = value\n",
    "        except:\n",
    "            pass\n",
    "    hg = row_data.find_all(class_ = 'hgraph')[1:]\n",
    "    values = [pull_value(hg, pos) for pos in range(0,43)]\n",
    "    # join both datasets: (area,population) + (rest of the data)\n",
    "    dictionary_copy = dictionary.copy()\n",
    "    dictionary_copy.update(dict(zip(keys,values)))\n",
    "    return dictionary_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.city-data.com/neighborhood/Albany-Park-Chicago-IL.html'\n",
    "pull_neighborhood_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_neighborhood_data('http://www.city-data.com/neighborhood/Brook-Park-Brook-Park-OH.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scrape List of Neighborhoods in Brook Park, OH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.city-data.com/neighborhood/Brook-Park-Brook-Park-OH.html\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data = soup.find(class_='row')\n",
    "row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = row_data.find(class_='content-item')\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract area and population\n",
    "d = {}\n",
    "for i in item.find_all('b'):\n",
    "    try:\n",
    "        key = i.text.strip()\n",
    "        value = i.next_sibling.strip()\n",
    "        d[key] = value\n",
    "    except:\n",
    "        pass\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull data from hgraph \n",
    "def pull_value(hg, item_pos):\n",
    "    return hg[item_pos].find('table').find_all('tr')[0].find_all('td')[1].text\n",
    "\n",
    "# test function above on another hgraph\n",
    "hg = row_data.find_all(class_ = 'hgraph')[1:]\n",
    "pull_value(hg,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull all data from the page\n",
    "keys = ['med household income'\n",
    "        ,'med rent'\n",
    "        ,'males'\n",
    "        ,'med age males'\n",
    "        ,'med age females'\n",
    "        ,'avg household size'\n",
    "        ,'pct family household'\n",
    "        ,'pct married couple'\n",
    "        ,'pct families with children'\n",
    "        ,'pct single mother'\n",
    "        ,'pct never married males > 15'\n",
    "        ,'pct never married females > 15'\n",
    "        ,'pct not speak English well'\n",
    "        ,'pct born in state'\n",
    "        ,'pct born in another us state'\n",
    "       ,'pct native residents born outside us'\n",
    "       ,'pct foreign born residents'\n",
    "       ,'avg number of cars houses'\n",
    "       ,'avg number of cars apts'\n",
    "       ,'pct units mortgage']\n",
    "values = [pull_value(hg, pos) for pos in range(0,20)]\n",
    "dict(zip(keys,values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both datasets: (area,population)+(rest of the data)\n",
    "z = d.copy()\n",
    "z.update(dict(zip(keys,values)))\n",
    "z\n",
    "# area in sq. miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract all data for a neighborhood from page URL\n",
    "\n",
    "keys = ['med household income'\n",
    "        ,'med rent'\n",
    "        ,'males'\n",
    "        ,'med age males'\n",
    "        ,'med age females'\n",
    "        ,'avg household size'\n",
    "        ,'pct family household'\n",
    "        ,'pct married couple'\n",
    "        ,'pct families with children'\n",
    "        ,'pct single mother'\n",
    "        ,'pct never married males > 15'\n",
    "        ,'pct never married females > 15'\n",
    "        ,'pct not speak English well'\n",
    "        ,'pct born in state'\n",
    "        ,'pct born in another us state'\n",
    "       ,'pct native residents born outside us'\n",
    "       ,'pct foreign born residents'\n",
    "       ,'avg number of cars houses'\n",
    "       ,'avg number of cars apts'\n",
    "       ,'pct units mortgage']\n",
    "\n",
    "def pull_neigh_data(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    row_data = soup.find(class_='row')\n",
    "    item = row_data.find(class_='content-item')\n",
    "    d = {}\n",
    "    for i in item.find_all('b'):\n",
    "        try:\n",
    "            key = i.text.strip()\n",
    "            value = i.next_sibling.strip()\n",
    "            d[key] = value\n",
    "        except:\n",
    "            pass\n",
    "    hg = row_data.find_all(class_ = 'hgraph')[1:]\n",
    "    values = [pull_value(hg, pos) for pos in range(0,20)]\n",
    "    z = d.copy()\n",
    "    z.update(dict(zip(keys,values)))\n",
    "    return z\n",
    "\n",
    "# test run on Murraywood\n",
    "url = \"http://www.city-data.com/neighborhood/Brook-Park-Brook-Park-OH.html\"\n",
    "\n",
    "pull_neigh_data(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scrape List of Neighborhoods in Illinois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of neighborhoods is available at the following url\n",
    "page_no = 1 # use only the first page for now\n",
    "url = \"http://www.city-data.com/indexes/neighborhoods/IL/%d/\"%page_no\n",
    "\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = soup.find_all('li')\n",
    "li[100] # show one of the neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prefix = 'http://www.city-data.com'\n",
    "\n",
    "# function returns neighborhood name and url for a list item\n",
    "def get_neigh_url(li_item):\n",
    "    value = url_prefix + li_item.find('a').get('href')\n",
    "    key = li_item.text\n",
    "    return (key,value)\n",
    "    \n",
    "get_neigh_url(li[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(page_no):\n",
    "    '''function to scrape all neighborhood names from one page identified by page_no'''\n",
    "    url = \"http://www.city-data.com/indexes/neighborhoods/IL/%d/\"%page_no\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    urls_dict = []\n",
    "    for li_item in soup.find_all('li'):\n",
    "        if li_item.text.find('Chicago, IL') >= 0: # Use only neighborhoods containing 'Westmont, IL' in their name\n",
    "            urls_dict.append(get_neigh_url(li_item))\n",
    "    return urls_dict\n",
    "\n",
    "# Example -- scrape page 2 from the website\n",
    "# urls_dict = scrape_page(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page2(page_no):\n",
    "    '''function to scrape all neighborhood names from one page identified by page_no'''\n",
    "    url = \"http://www.city-data.com/indexes/neighborhoods/OH/%d/\"%page_no\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    urls_dict = []\n",
    "    for li_item in soup.find_all('li'):\n",
    "        if li_item.text.find('Brook Park, OH') >= 0:\n",
    "            urls_dict.append(get_neigh_url(li_item))\n",
    "    return urls_dict\n",
    "\n",
    "# Example -- scrape page 2 from the website\n",
    "# urls_dict = scrape_page(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_pages():\n",
    "    urls_dict = []\n",
    "    for page_no in range(1,8):\n",
    "        scraped = scrape_page(page_no)\n",
    "        urls_dict += scraped\n",
    "        print(f'Processed page {page_no} of 7\\n')\n",
    "        \n",
    "    # save neighborhood names and urls for later usage\n",
    "    with open('urls_dict.pickle','wb') as f:\n",
    "        pickle.dump(urls_dict, f)\n",
    "    return urls_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scrape Socioeconomic Data (production)\n",
    "\n",
    "+ Now that we have the full list of urls and neighborhood names, we can scrape socioeconomic data for each neighborhood in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_neighborhood(urls):\n",
    "    lst = []\n",
    "    count = 0\n",
    "    for name, url in urls:\n",
    "        try:\n",
    "            df = pull_neighborhood_data(url)\n",
    "            df['neighborhood'] = name\n",
    "            lst.append(df)\n",
    "            count += 1\n",
    "            print(f'{name} processed {count}, now waiting...')\n",
    "        except:\n",
    "            print(f'{name} unable to pull data')\n",
    "    df_neighborhoods = pd.DataFrame(lst)\n",
    "    return df_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neighborhoods = scrape_neighborhood(scrape_all_pages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neighborhoods.to_csv('./data/neighborhoods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_neighborhoods.copy()\n",
    "df_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Austin neighborhood to df\n",
    "row = pull_neighborhood_data('http://www.city-data.com/neighborhood/Brook-Park-Brook-Park-OH.html')\n",
    "# if the neighborhood has not been added, add it to the df\n",
    "if len(df_copy[df_copy['neighborhood'] == 'Brook Park, Brook Park, OH']) == 0:\n",
    "    df_copy = df_copy.append(pd.Series(row), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[df_copy['neighborhood'] == 'Brook Park, Brook Park, OH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv('./data/Brook_Park_neighborhoods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Brook_Park_neighborhoods.csv',index_col = 0)\n",
    "df = df.rename(columns = {'neighborhood':'Neighborhood'})\n",
    "df['Neighborhood'] = df['Neighborhood'].apply(lambda x:x.replace(' neighborhood in',','))\n",
    "df = df.set_index('Neighborhood')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scrape Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_venues():\n",
    "    with open('./data/urls_dict.pickle','rb') as f:\n",
    "        urls_dict = pickle.load(f)\n",
    "    names = []\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "\n",
    "    for u in urls_dict:\n",
    "        try:\n",
    "            name = u[0].replace(' neighborhood in',',') # make name look like an address\n",
    "            lat = get_coords(name)[1]\n",
    "            lng = get_coords(name)[2]\n",
    "            names.append(name)\n",
    "            latitudes.append(lat)\n",
    "            longitudes.append(lng)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    coords = list(set(zip(names, latitudes, longitudes))) # remove duplicates\n",
    "    # save coords for later use\n",
    "    with open('coords.pickle','wb') as f:\n",
    "        pickle.dump(coords,f)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pull Venus Data from Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_venues(scrape_venues, client, radius, limit):\n",
    "    \n",
    "    with open('./data/coords.pickle','rb') as f:\n",
    "        coords = pickle.load(f)\n",
    "        \n",
    "    venues_lst = []\n",
    "    for name, lat, lng in coords:\n",
    "        print(name)\n",
    "        try:\n",
    "            latitude_str = str(lat)\n",
    "            longitude_str = str(lng)\n",
    "            ll = latitude_str + ',' + longitude_str       \n",
    "            venues = client.venues.explore(params={\n",
    "                'll':ll,\n",
    "                'limit':100,\n",
    "                'intent' : 'browse',\n",
    "                'radius':8000,\n",
    "            })\n",
    "            venues = venues['groups'][0]['items']\n",
    "            # return only relevant information for each nearby venue\n",
    "            venues_lst.append([(\n",
    "                        name, \n",
    "                        lat, \n",
    "                        lng, \n",
    "                        venue['venue']['name'], \n",
    "                        venue['venue']['location']['lat'], \n",
    "                        venue['venue']['location']['lng'],  \n",
    "                        venue['venue']['categories'][0]['name']) for venue in venues])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        nearby_venues = pd.DataFrame([item for venue_list in venues_lst for item in venue_list])\n",
    "        nearby_venues.columns = ['Neighborhood', \n",
    "                                 'Neighborhood Latitude', \n",
    "                                 'Neighborhood Longitude', \n",
    "                                 'Venue', \n",
    "                                 'Venue Latitude', \n",
    "                                 'Venue Longitude', \n",
    "                                 'Venue Category']\n",
    "    return nearby_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = get_nearby_venues(scrape_venues(), foursquare_api(), radius=500, limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues.to_csv('./data/venues.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues.groupby('Neighborhood').count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert venue category to one hot encoding\n",
    "venues_onehot = pd.get_dummies(venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "# add neighborhood column back to dataframe\n",
    "venues_onehot['Neighborhood'] = venues['Neighborhood']\n",
    "# reorder columns\n",
    "# cols = list(venues_onehot.columns)\n",
    "# cols = [cols[-1]] + cols[:-1]\n",
    "# venues_onehot = venues_onehot[cols]\n",
    "\n",
    "field_ix = list(venues_onehot.columns).index('Neighborhood')\n",
    "fixed_columns = [venues_onehot.columns[field_ix]]\\\n",
    "            +list(venues_onehot.columns[:field_ix])\\\n",
    "            +list(venues_onehot.columns[(field_ix+1):])\n",
    "venues_onehot = venues_onehot[fixed_columns]\n",
    "\n",
    "\n",
    "venues_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of venues in each category\n",
    "venues_grouped = venues_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "venues_grouped = venues_grouped.set_index('Neighborhood')\n",
    "venues_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Venues Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Socioeconmic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neighborhoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['avg household size',\n",
    "#         'avg number of cars apts',\n",
    "#         'avg number of cars houses',\n",
    "#         'males',\n",
    "#         'med age females',\n",
    "#         'med age males',\n",
    "#         'med household income',\n",
    "#         'med rent',\n",
    "#         'pct born in another us state',\n",
    "#         'pct born in state',\n",
    "#         'pct families with children',\n",
    "#         'pct family household',\n",
    "#         'pct foreign born residents',\n",
    "#         'pct married couple',\n",
    "#         'pct native residents born outside us',\n",
    "#         'pct never married females > 15',\n",
    "#         'pct never married males > 15',\n",
    "#         'pct not speak English well',\n",
    "#         'pct single mother',\n",
    "#         'pct units mortgage']\n",
    "# df_neighborhoods = df_neighborhoods[cols]\n",
    "# df_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both datasets\n",
    "df_neighs_venues = df_neighborhoods.join(venues_grouped, how = 'inner')\n",
    "df_neighs_venues = df_neighs_venues.rename(columns = {'Area:':'area','Population:':'population'})\n",
    "df_neighs_venues.to_csv('./data/neighs_venues.csv')\n",
    "df_neighs_venues.head()\n",
    "df_neighs_venues.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Methodology\n",
    "---\n",
    "## Clean & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/neighs_venues.csv',index_col = 0)\n",
    "df = df.rename(columns = {'Area:':'area','Population:':'population'})\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any neighborhood that may have NaN's\n",
    "df.dropna(inplace = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ' people' from household field and convert to float\n",
    "def household_process(item):\n",
    "    if type(item) == float:\n",
    "        return item\n",
    "    try:\n",
    "        if len(item) > 6:\n",
    "            return float(item[:-6])\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "df['avg household size'] = df['avg household size'].apply(household_process).astype(float)\n",
    "df.loc[df['avg household size'] == 0,'avg household size'] = 1 # make household size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ' years' from fields\n",
    "def remove_years(item):\n",
    "    if type(item) == float:\n",
    "        return item\n",
    "    try:\n",
    "        if len(item) > 6:\n",
    "            return float(item[:-6])\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "for f in ['med age males','med age females']:\n",
    "    df[f] = df[f].apply(remove_years).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove $ sign\n",
    "def remove_dollar(item):\n",
    "    if type(item) == float:\n",
    "        return item\n",
    "    try:\n",
    "        return float(item)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if len(item) > 1:\n",
    "            item = ''.join(item.split(','))[1:]\n",
    "            return float(item)\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "for f in ['med household income','med rent']:\n",
    "    df[f] = df[f].apply(remove_dollar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove % symbols from fields\n",
    "def remove_percent(item):\n",
    "    if type(item) == float:\n",
    "        return item\n",
    "    try:\n",
    "        return float(item)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if len(item) > 1:\n",
    "            return float(item[:-1])\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "for f in ['pct born in another us state','pct born in state'\n",
    "         ,'pct families with children','pct family household'\n",
    "         ,'pct foreign born residents','pct married couple'\n",
    "         ,'pct native residents born outside us','pct never married females > 15'\n",
    "         ,'pct never married males > 15','pct not speak English well','pct units mortgage'\n",
    "         ,'pct single mother','pct born in another us state'\n",
    "         ]:\n",
    "    df[f] = df[f].apply(remove_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ',' from population field\n",
    "df['population'] = df.population.apply(lambda x:int(''.join(x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to process avg number of cars\n",
    "def try_to_convert(item):\n",
    "    try:\n",
    "        return float(item)\n",
    "    except:\n",
    "        return None\n",
    "df['avg number of cars apts'] = df['avg number of cars apts'].apply(try_to_convert)\n",
    "df['avg number of cars houses'] = df['avg number of cars houses'].apply(try_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to convert males field to a number\n",
    "df['males'] = df['males'].apply(try_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take another look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Fill NaNs with means\n",
    "\n",
    "Several fields ended up having NaN's, where data could not be converted to numeric format:\n",
    "* Avg number of cars -- fill with avg across the dataset\n",
    "* Males -- fill with population/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'avg number of cars apts'\n",
    "df[field].fillna(df[field].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'avg number of cars houses'\n",
    "df[field].fillna(df[field].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.isnull().any(axis = 1),'males'] = df.loc[df.isnull().any(axis = 1),'population']/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('neighborhoods_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Remove columns with sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/neighborhoods_clean.csv',index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate which venue columns have only few occurrences\n",
    "socioeconomic_cols = list(df.columns[:22])\n",
    "venues_cols = list(df.iloc[:,22:].sum().sort_values(0, ascending = False).index[:10]) # ten most common venues)\n",
    "cols_to_keep = socioeconomic_cols + venues_cols\n",
    "cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df[cols_to_keep]\n",
    "df_dropped.to_csv('./data/chicago_neighborhoods_top_10')\n",
    "df_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.area.plot(kind='hist', bins = 100, figsize = (5,3))\n",
    "plt.title('Neighborhood Areas')\n",
    "plt.xlabel('Area, sq. miles')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.area.plot(kind='hist', bins = 300, figsize = (5,3))\n",
    "plt.title('Neighborhood Areas')\n",
    "plt.xlabel('Area, acres')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ It appears that area field has outliers. Let's explore it further via boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.area.plot(kind='box',figsize = (10,3), vert = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ There is something going on here. Assuming that one house takes approximately 0.5 acres., let's discard neighborhoods with less than 4 houses (2/640 sq. miles):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas = df[df.area >= 2.0/640]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Also, the neighborhood with the largest area is O'Hare in Chicago:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas[df_areas.area > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas.area.plot(kind='box', figsize = (10,3), vert = False)\n",
    "# plt.xlim([0,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas[df_areas.area > 0.1].area.plot(kind='box', vert = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ O'Hare neighborhood is the top outlier and majority of neighborhoods in Chicago have way smaller area. One possible reason is that neighborhoods in the dataset are 'split', i.e. multiple rows represent the same neighborhood. Area will be excluded from further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Average household size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg household size'].plot(kind='hist', bins = 50, figsize = (10,5))\n",
    "plt.xlabel('Average household size')\n",
    "plt.title('Average household size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['avg household size'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Neighborhoods with more than 10 people on average per household do not appear legit. Let's clean them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household = df[(df['avg household size'] < 10)]\n",
    "df_household.shape\n",
    "df_household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household['avg household size'].plot(kind='hist', bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Average number of cars in appartments and houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household.loc[:,'avg number of cars'] = (df_household['avg number of cars apts'] + df_household['avg number of cars apts'])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household['avg number of cars'].plot(kind='hist', bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = df_household[df_household['avg number of cars'] < 5]\n",
    "df_cars['avg number of cars'].plot(kind='hist', bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Medium Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['med age'] = (df_cars['med age females'] + df_cars['med age males'])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['med age'].plot(kind='hist', bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ A few neighborhoods appear to have suspiciously young residents. Perhaps in some neighborhoods, the number of children is higher than the number of adults?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Median Household income and rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['med household income'].plot(kind='hist', bins = 20)\n",
    "plt.xlabel('Income')\n",
    "plt.title('Median Household Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['med rent'].plot(kind='hist', bins = 20)\n",
    "plt.xlabel('Rent')\n",
    "plt.title('Median Rent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Families with children, family household, married couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct families with children'].plot(kind='hist', bins = 10)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent families with children')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct family household'].plot(kind='hist', bins = 20)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent family household')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct married couple'].plot(kind='hist', bins = 10)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent married couple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Percents should not exceed 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct never married females > 15'].plot(kind='hist', bins = 15)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent never married females older than 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct never married males > 15'].plot(kind='hist', bins = 15)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent never married males older than 15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Percent residents born in other states or outside the U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct born in another us state'].plot(kind='hist', bins = 15)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent born in another U.S. state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct born in state'].plot(kind='hist', bins = 15)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent born in IL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct foreign born residents'].plot(kind='hist', bins = 10)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent foreign born residents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct native residents born outside us'].plot(kind='hist', bins = 10)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent native residents born outside of the U.S.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct not speak English well'].plot(kind='hist', bins = 15)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent residents who do not speak English well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct single mother'].plot(kind='hist', bins = 15)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent single mother households')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars['pct units mortgage'].plot(kind='hist', bins = 15)\n",
    "plt.xlabel('percent')\n",
    "plt.title('Percent units with mortgage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_cars[df_cars['pct units mortgage'] < 100]\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for further use\n",
    "df_clean.to_csv('./data/chicago_neighborhoods_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/chicago_neighborhoods_clean.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
